## 声音的物理特性
      ** 声波**的三要素是频率、振幅和波形，频率代表音阶的高低，振幅代表响度，波形代表音色。
      **频率**（过零率）越高，波长就越短。低频声响的波长则较长，所以其可以更容易地绕过障碍物，因此能量衰减就小，声音就会传得远，反之则会得到完全相反的结论。  
      **响度**其实就是能量大小的反映，用不同的力度敲击桌子，声音的大小势必也会不同。在生活中，分贝常用于描述响度的大小。声音超过一定的分贝，人类的耳朵就会受不了。
      **音色**其实也不难理解，在同样的音调（频率）和响度（振幅）下，钢琴和小提琴的声音听起来是完全不相同的，因为它们的音色不同。波的形状决定了其所代表声音的音色，钢琴和小提琴的音色不同就是因为它们的介质所产生的波形不同。人类耳朵的听力有一个频率范围，大约是20Hz～20kHz，不过，即使是在这个频率范围内，不同的频率，听力的感觉也会不一样，业界非常著名的等响曲线，就是用来描述等响条件下声压级与声波频率关系的，如图1-2所示。
![image.png](https://cdn.nlark.com/yuque/0/2023/png/12719710/1700205050545-ddd938ba-1717-42f1-a695-2c607c11be01.png#averageHue=%23eaeaea&clientId=u68a90cf9-2e9a-4&from=paste&height=740&id=u2065dfad&originHeight=740&originWidth=817&originalType=binary&ratio=1&rotation=0&showTitle=false&size=397474&status=done&style=none&taskId=uf9888729-5c2e-4ad5-a2bc-88b1bd8d6a9&title=&width=817)
      从图1-2中可以看出，人耳对3～4kHz频率范围内的声音比较敏感，而对于较低或较高频率的声音，敏感度就会有所减弱；在声压级较低时，听觉的频率特性会很不均匀；而在声压级较高时，听觉的频率特性会变得较为均匀。频率范围较宽的音乐，其声压以80～90dB为最佳，超过90dB将会损害人耳（105dB为人耳极限）。
      音调是指声音的高低，与频率有关。物体振动的快，发出声音的音调就高；振动的慢，发出声音的音调就低。声音频率的高低叫做音调，是声音的三个主要的主观属性之一。音调又称声音的尖细。音调高的声音比较尖，人感到刺耳。音调低的声音比较钝，人感觉到厚。音调不同声音的波形也就不同，波形越密的，音调越高。波形越疏的，音调越低。
      响度是指声音的强弱，与振幅有关。振幅越大，响度越大；振幅越小，响度越小。 声音的强弱叫做响度。响度是感觉判断的声音强弱，即声音响亮的程度，根据它可以把声音排成由轻到响的序列。
      音色是声音的特征，与发声体的材料和结构有关。 音色是指不同声音表现在波形方面总是有与众不同的特性，不同的物体振动都有不同的特点。
      前面提到过分贝，那么什么是分贝呢？分贝是用来表示声音强度的单位。日常生活中听到的声音，若以声压值来表示，由于其变化范围非常大，可以达到六个数量级以上，同时由于我们的耳朵对声音信号强弱刺激的反应不是线性的（1.1节中提到过等响曲线），而是呈对数比例关系，所以引入分贝的概念来表达声学量值。所谓分贝是指两个相同的物理量（例如，A1和A0）之比取以10为底的对数并乘以10（或20），即：
> N= 10 * lg（A1 / A0）

分贝符号为“dB”，它是无量纲的。
式中A0是基准量（或参考量），A1是被量度量。
## 麦克风是如何采集声音的
      麦克风（又称微音器或话筒，正式的中文名是传声器），译自英文microphone，是一种将声音转换成电子信号的换能器。根据麦克风的制作原理，分为以下几类：
**动圈麦克风**
      动圈式麦克风基本构造包含线圈、振膜、永久磁铁三部分。当声波进入麦克风，振膜受到声波的压力而产生振动，与振膜连接在一起的线圈则开始在磁场中移动，根据法拉第定律以及楞次定律，线圈会产生感应电流。
动圈式麦克风因为含有线圈和磁铁，不像电容式麦克风轻便，灵敏度较低，高低频响应表现较差。优点是声音较为柔润，适合用来收录人声。
![](https://cdn.nlark.com/yuque/0/2023/png/12719710/1700206806700-dfd5034b-b234-44e8-84fb-4160b104604b.png#averageHue=%23ede8e7&clientId=u68a90cf9-2e9a-4&from=paste&id=u543087ff&originHeight=205&originWidth=320&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u72b0835e-689d-4902-ba03-1397c675201&title=)
> 1、声波 2、振动膜 3、线圈 4、磁铁 5、输出信号

**电容式麦克风**
      电容式麦克风并没有线圈及磁铁，靠着电容两片隔板间距离的改变来产生电压变化。当声波进入麦克风，振动膜产生振动，因为基板是固定的，使得振动膜和基板之间的距离会随着振动而改变，根据电容的特性，当两块隔板距离发生变化时，电容值C会产生改变，又由于Q = C * V，当C改变时就会造成电量Q的改变。因为在电容式麦克风中需要维持固定的极板电压V，所以此类麦克风需要额外的电源才能运作，一般常见的电源为电池。电容式麦克风因灵敏度较高，常用于高质量的录音。
![](https://cdn.nlark.com/yuque/0/2023/png/12719710/1700206806568-a4a87f6e-91a2-4450-b1d4-062828be66e1.png#averageHue=%23f0ecec&clientId=u68a90cf9-2e9a-4&from=paste&id=u08b79b2b&originHeight=206&originWidth=320&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u84323fbd-89ed-4b19-abd4-7c6180cf4af&title=)
> 1、声波 2、振动膜 3、基板 4、电池 5、电阻 6、输出信号

**驻极体电容麦克风**
      电容式麦克风一般需要额外的电源才能运作，但是驻极体电容麦克风却可以不需要额外的电源。驻极体又叫“永电体”，本身会带有固定数量的电荷数，整个线路没有电量消耗（线路去除上图的电池和电阻），根据公式：Q =CU 所以当C变化时必然引起电容器两端电压U的变化，从而输出电信号，实现声—电的变换。由于实际电容器的电容量很小，输出的电信号极为微弱，输出阻抗极高，可达数百兆欧以上。因此，它不能直接与放大电路相连接，必须连接阻抗变换器。通常用一个专用的场效应管和一个二极管复合组成阻抗变换器。由于场效应管是有源器件，需要一定的偏置和电流才可以工作在放大状态，因此，驻极体话筒都要加一个直流偏置才能工作。
**微机电麦克风**
       微机电麦克风指使用微机电技术做成的麦克风，也称麦克风芯片或硅麦克风。 微机电麦克风的压力感应膜是以微机电技术直接蚀刻在硅芯片上，此集成电路芯片通常也集成入一些相关电路，如前置放大器。 大多数微机电麦克风的设计，在基本原理上是属于电容式麦克风的一种变型。 微机电麦克风也常内置模拟数字转换器，直接输出数字信号，成为数字式麦克风，以利与现今的数字电路连接。微机电麦克风的主要应用于部分的手机、PDA等小型移动产品。
      还有其他类型的麦克风在这就不多做讲述。
麦克风是一种传感器，用于将声音转换成电信号。它包含以下主要组件：

1.  **膜片或振动体：** 麦克风的主要部分是一个能够感知声音压力变化的薄膜片或振动体。当周围的空气因声波振动时，膜片或振动体也会随之振动。 
2.  **磁圈或电容器：** 麦克风的膜片或振动体与磁圈或电容器等部件相连接。当膜片或振动体振动时，它们会改变与磁圈或电容器的相对位置或距离，导致电信号的变化。 
3.  **电路：** 麦克风内部有电路，将振动产生的电信号放大并转换成可用的电流或电压信号。这个信号即是声音的电信号表示。 

当声音波通过麦克风时，它使得麦克风内部的膜片或振动体随着声音的变化而振动。这个振动产生的变化被转换为电信号，并经过内部电路放大和处理，最终输出的电信号被传送到其他设备，如扬声器、录音设备或计算机，进而被转换为可听的声音或数字化的声音数据。
## 麦克风降噪
      随着科技的发展，现在即使在非常嘈杂的环境下，接听电话的另一方也能听得清清楚楚，这主要得益于手机降噪技术的发展。在现在的手机我们常常看到不仅仅只有一个麦克风，而是有2个甚至是3个，而这多出来的几个就是手机降噪的关键。
![](https://cdn.nlark.com/yuque/0/2023/jpeg/12719710/1700207352080-a322466f-83e7-42e2-bac7-90f76981911f.jpeg#averageHue=%23efefef&clientId=u68a90cf9-2e9a-4&from=paste&id=u6c1c6af2&originHeight=412&originWidth=560&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=u31000dfc-8452-41c3-b186-49997d54319&title=)
      一般来说手机都有两个麦克风，顶部和底部都各有一个。这两个麦看起来都非常小，但是两者的作用有着明显的区别，其中底部的麦是用来提供清晰通话，而顶部的麦是用来消除噪音。
      由于顶部和底部在通话时距离音源的距离不同，所以两个麦拾取的音量大小也是有不同的，利用这个差别，我们就可以过滤掉噪声保留人声了。在打电话时，两个麦克风所拾取的背景噪声音量是基本相同的，而记录的人声会有6dB左右的音量差。顶端麦收集噪声后，通过解码生成补偿信号后就可以用来消除噪音了。
手机麦克风的降噪通常利用以下技术来实现：

1.  **多个麦克风阵列：** 现代手机通常配备了多个麦克风，位于不同位置。这些麦克风可以捕捉声音来自不同方向的声波。通过分析和比较多个麦克风的接收信号，系统可以识别并消除背景噪音，只保留目标声源。 
2.  **数字信号处理（DSP）：** 麦克风信号经过数字信号处理器（DSP）处理，采用各种算法和技术来降低噪音。这包括利用降噪算法来区分声音和噪音，并尝试消除或减少背景噪音的影响。 
3.  **智能软件算法：** 基于机器学习和人工智能的技术，手机麦克风的降噪功能越来越智能化。这些算法能够通过识别特定类型的噪音，例如风噪声、车辆噪音或环境背景噪音，并尝试去除它们，保留人类声音。 
4.  **声学设计：** 手机制造商在设计手机时也会考虑如何减少环境噪音的影响。使用各种技术来隔离麦克风，优化布局或加入物理隔音设计，以最大程度上减少噪音对麦克风的影响。 

这些技术的结合帮助手机麦克风在录音时更准确地捕捉到人声或目标声音，并尽可能减少环境噪音的影响，提高了通话质量和音频录制的清晰度。
## 回声
       回声（或称回音）是指障碍物对声音的反射。声波在遇到障碍物时，一部分声波会穿过障碍物，而另一部分声波会反射回来形成回声。若障碍物具有坚硬光滑的表面易产生回声；反之，具有柔软的表面则易吸收声音；另外，粗糙的表面易散射声音。回声相比那些直接传播的声音所经过的路程更长，所以会比直接传播的声音晚被听到。如果两列声波的时间间隔小于0.1秒，人耳边无法分辨，只能听到被延长的声音。因为室温（20℃）时空气中的声速是343米每秒，所以站在声源处的人要听到回声需要障碍物到声源的距离至少17米。
**回声消除**
       很多时候直播有连麦的需求，这时候就需要对采集的声音进行回声消除。当处在连麦的情况下，手机一边播放对方的声音，一边用麦克风进行采集，然后又将采集的声音传送给对方，这样的话对方就会听到自己的回声，由于这个循环回路一直进行，从而就会使得回声越来越多，最后出现嗡鸣声。
       回声消除就是在麦克风录制外音的时候去除掉手机自身播放出来的声音，这样就将对方的声音从采集的声音中过滤出去，从而就避免了回声的产生。下面一张图片很好展示了回声消除的机制。
![](https://cdn.nlark.com/yuque/0/2023/png/12719710/1700207352153-772ec1c0-889b-49b3-a2d1-68fff4a704af.png#averageHue=%23f0f0f0&clientId=u68a90cf9-2e9a-4&from=paste&id=ue9ae6f77&originHeight=290&originWidth=472&originalType=url&ratio=1&rotation=0&showTitle=false&status=done&style=none&taskId=ub617694c-57f0-4cbc-a4f5-da40666cdbf&title=)
      在近端，麦克风会采集到扬声器播放出来的远端声音，假设这路声音为y(n)，当然由于需要将远端传来播放出来，我们当然能得到远端传来的声音信号，假设这路声音为x(n)。不难发现x(n)经过扬声器的播放，然后经过空气的传播，最后被麦克风采集，然后变为y(n)，x(n)和y(n)具有明显的相关性。假设麦克风采集到的总声音信号为z(n)，这时候需要通过自适应滤波器根据x(n)找出z(n)中的y(n)，然后从z(n)中过滤掉y(n)。

麦克风的回声消除是一种技术，旨在减少或消除由于声音在录音环境中反射和传播而产生的回声。这种技术通常采用以下方法：

1.  **回声取消器（Echo Cancellation）：** 这是最常见的方法之一。回声取消器通过比较从扬声器输出的声音与麦克风接收到的声音，并识别它们之间的差异。然后，它会尝试逆向处理这种差异，消除或减弱麦克风捕捉到的来自扬声器的声音。 
2.  **自适应滤波器：** 使用自适应滤波器，系统能够根据实时环境中的声音特征来调整滤波器参数。这使得系统能够更好地识别和消除特定频率上的回声，提高消除效果。 
3.  **延迟和混响处理：** 通过控制信号的延迟和混响程度，可以减少回声的出现。这些技术有助于模糊回声，使其不那么明显，从而减轻其对录音的影响。 
4.  **声学建模和识别：** 通过对录音环境进行声学建模，系统能够识别声音传播的路径和回声发生的可能性。基于这些模型，系统可以有针对性地调整声音处理方法，以最大程度地减少回声。 

这些技术通常作为音频处理软件或硬件的一部分，用于在通话、录音或其他声音采集场景中减少或消除回声。虽然回声消除技术能够有效减少回声，但在极端复杂的环境或特殊情况下可能无法完全消除。
## 数字音频
      为了将模拟信号数字化，本节将分3个概念对数字音频进行讲解，分别是**采样**、**量化**和**编码**。
      ![image.png](https://cdn.nlark.com/yuque/0/2023/png/12719710/1700208365085-8ca358f7-9c07-4688-83fc-5e0a0f077255.png#averageHue=%23f7f7f7&clientId=u68a90cf9-2e9a-4&from=paste&height=411&id=MOUqu&originHeight=411&originWidth=531&originalType=binary&ratio=1&rotation=0&showTitle=false&size=58917&status=done&style=none&taskId=u77cd7aa0-89a5-4681-999b-09ca2d00348&title=&width=531)
      首先要对模拟信号进行采样，所谓采样就是在时间轴上对信号进行数字化。根据奈奎斯特定理（也称为采样定理），按比声音最高频率高2倍以上的频率对声音进行采样（也称为AD转换），对于高质量的音频信号，其频率范围（人耳能够听到的频率范围）是20Hz～20kHz，所以采样频率一般为44.1kHz，这样就可以保证采样声音达到20kHz也能被数字化，从而使得经过数字化处理之后，人耳听到的声音质量不会被降低。而所谓的44.1kHz就是代表1秒会采样44100次（如图1-5所示）。
      那么，具体的每个采样又该如何表示呢？这就涉及将要讲解的第二个概念：量化。量化是指在幅度轴上对信号进行数字化，比如用16比特的二进制信号来表示声音的一个采样，而16比特（一个short）所表示的范围是[-32768，32767]，共有65536个可能取值，因此最终模拟的音频信号在幅度上也分为了65536层（如图1-6所示）。既然每一个量化都是一个采样，那么这么多的采样该如何进行存储呢？这就涉及将要讲解的第三个概念：编码。
![image.png](https://cdn.nlark.com/yuque/0/2023/png/12719710/1700205537250-ce8fcfce-fafb-45e7-ac71-5ed1fe6b007b.png#averageHue=%23f5f5f5&clientId=u68a90cf9-2e9a-4&from=paste&height=686&id=ylibD&originHeight=686&originWidth=789&originalType=binary&ratio=1&rotation=0&showTitle=false&size=148444&status=done&style=none&taskId=ud2a0e99b-a0f4-44ee-a546-467ab87bd3e&title=&width=789)
       所谓编码，就是按照一定的格式记录采样和量化后的数字数据，比如顺序存储或压缩存储，等等。这里面涉及了很多种格式，通常所说的音频的裸数据格式就是脉冲编码调制（Pulse Code Modulation，PCM）数据。描述一段PCM数据一般需要以下几个概念：量化格式（sampleFormat）、采样率（sampleRate）、声道数（channel）。以CD的音质为例：量化格式（有的地方描述为位深度）为16比特（2字节），采样率为44100，声道数为2，这些信息就描述了CD的音质。而对于声音格式，还有一个概念用来描述它的大小，称为数据比特率，即1秒时间内的比特数目，它用于衡量音频数据单位时间内的容量大小。而对于CD音质的数据，比特率为多少呢？计算如下：44100 * 16 * 2 = 1378.125kbps那么在1分钟里，这类CD音质的数据需要占据多大的存储空间呢？
      既然每一个量化都是一个采样，那么这么多的采样该如何进行存储呢？这就涉及将要讲解的第三个概念：编码。所谓编码，就是按照一定的格式记录采样和量化后的数字数据，比如顺序存储或压缩存储，等等。这里面涉及了很多种格式，通常所说的音频的裸数据格式就是脉冲编码调制（Pulse Code Modulation，PCM）数据。描述一段PCM数据一般需要以下几个概念：量化格式（sampleFormat）、采样率（sampleRate）、声道数（channel）。以CD的音质为例：量化格式（有的地方描述为位深度）为16比特（2字节），采样率为44100，声道数为2，这些信息就描述了CD的音质。而对于声音格式，还有一个概念用来描述它的大小，称为数据比特率，即1秒时间内的比特数目，它用于衡量音频数据单位时间内的容量大小。而对于CD音质的数据，比特率为多少呢？计算如下：
>     44100 * 16 * 2 = 1378.125kbps

    那么在1分钟里，这类CD音质的数据需要占据多大的存储空间呢？
>    1378.125 * 60 / 8 / 1024 = 10.09MB

      当然，如果sampleFormat更加精确（比如用4字节来描述一个采样），或者sampleRate更加密集（比如48kHz的采样率），那么所占的存储空间就会更大，同时能够描述的声音细节就会越精确。存储的这段二进制数据即表示将模拟信号转换为数字信号了，以后就可以对这段二进制数据进行存储、播放、复制，或者进行其他任何操作。
## 音频编码
      前边提到了CD音质的数据采样格式，曾计算出每分钟需要的存储空间约为10.1MB，如果仅仅是将其存放在存储设备（光盘、硬盘）中，可能是可以接受的，但是若要在网络中实时在线传播的话，那么这个数据量可能就太大了，所以必须对其进行压缩编码。
      压缩编码的基本指标之一就是压缩比，压缩比通常小于1（否则就没有必要去做压缩，因为压缩就是要减小数据容量）。压缩算法包括有损压缩和无损压缩。无损压缩是指解压后的数据可以完全复原。在常用的压缩格式中，用得较多的是有损压缩，有损压缩是指解压后的数据不能完全复原，会丢失一部分信息，压缩比越小，丢失的信息就越多，信号还原后的失真就会越大。根据不同的应用场景（包括存储设备、传输网络环境、播放设备等），可以选用不同的压缩编码算法，如PCM、WAV、AAC、MP3、Ogg等。
     压缩编码的原理实际上是压缩掉冗余信号，冗余信号是指不能被人耳感知到的信号，包含人耳听觉范围之外的音频信号以及被掩蔽掉的音频信号等。而被掩蔽掉的音频信号则主要是因为人耳的掩蔽效应，主要表现为频域掩蔽效应与时域掩蔽效应，无论是在时域还是频域上，被掩蔽掉的声音信号都被认为是冗余信息，不进行编码处理。
下面介绍几种常用的压缩编码格式。

1. WAV编码PCM（脉冲编码调制）是Pulse Code Modulation的缩写。前面已经介绍过PCM大致的工作流程，而WAV编码的一种实现（有多种实现方式，但是都不会进行压缩操作）就是在PCM数据格式的前面加上44字节，分别用来描述PCM的采样率、声道数、数据格式等信息。特点：音质非常好，大量软件都支持。适用场合：多媒体开发的中间文件、保存音乐和音效素材。

       ![image.png](https://cdn.nlark.com/yuque/0/2023/png/12719710/1700208811344-e77fc2a0-6263-46b9-bb4b-ad86dac45f80.png#averageHue=%23bfe4c0&clientId=u68a90cf9-2e9a-4&from=paste&height=460&id=qptVf&originHeight=460&originWidth=700&originalType=binary&ratio=1&rotation=0&showTitle=false&size=185100&status=done&style=none&taskId=u7e64c310-c41f-427f-9e9f-1a7fd90ba2b&title=&width=700)

2. MP3编码MP3具有不错的压缩比，使用LAME编码（MP3编码格式的一种实现）的中高码率的MP3文件，听感上非常接近源WAV文件，当然在不同的应用场景下，应该调整合适的参数以达到最好的效果。特点：音质在128Kbit/s以上表现还不错，压缩比比较高，大量软件和硬件都支持，兼容性好。适用场合：高比特率下对兼容性有要求的音乐欣赏。
3. AAC编码AAC是新一代的音频有损压缩技术，它通过一些附加的编码技术（比如PS、SBR等），衍生出了LC-AAC、HE-AAC、HE-AAC v2三种主要的编码格式。LC-AAC是比较传统的AAC，相对而言，其主要应用于中高码率场景的编码（≥80Kbit/s）；HE-AAC（相当于AAC+SBR）主要应用于中低码率场景的编码（≤80Kbit/s）；而新近推出的HE-AAC v2（相当于AAC+SBR+PS）主要应用于低码率场景的编码（≤48Kbit/s）。事实上大部分编码器都设置为≤48Kbit/s自动启用PS技术，而>48Kbit/s则不加PS，相当于普通的HE-AAC。特点：在小于128Kbit/s的码率下表现优异，并且多用于视频中的音频编码。适用场合：128Kbit/s以下的音频编码，多用于视频中音频轨的编码。

当涉及音频编码时，常见的比较方面包括音频质量、文件大小、压缩率、适用性以及对各种音频类型的表现。

1.  **音频质量：** 不同编码方式对音频质量的影响不同。一些编码方式（如FLAC、WAV）提供无损压缩，保留了原始音频的全部细节。其他编码方式（如MP3、AAC）提供有损压缩，可能会在压缩过程中丢失一些细微的音频信息。 
2.  **文件大小：** 不同编码方式导致的文件大小差异很大。无损编码方式（例如FLAC）的文件大小通常比有损编码方式（例如MP3、AAC）大得多，因为前者保留了更多的音频信息。 
3.  **压缩率：** 有损编码方式以更高的压缩率生成较小的文件，但会损失一些音频细节。无损编码方式可以获得更高的音质，但文件大小更大。 
4.  **适用性：** 不同编码方式适用于不同的场景。有损编码方式（如MP3、AAC）适合于流媒体、移动设备等需要较小文件大小的情况。无损编码方式（如FLAC）适合于音乐爱好者、专业录音等注重高质量音频的场景。 
5.  **对各种音频类型的表现：** 不同编码方式可能对各种音频类型的表现有所差异。有些编码方式在特定类型的音频（如人声、古典音乐、电子音乐等）上表现更好，而在其他类型上则可能效果较差。 

这些是通常用于比较音频编码方式的关键方面，选择适合你需求的编码方式要考虑这些因素。
## 推荐阅读
[音频格式介绍和说明](https://zhuanlan.zhihu.com/p/182820185)
[音频编码：入门看这篇就够了丨音视频基础](https://zhuanlan.zhihu.com/p/499760382?utm_id=0)

