iOS中实现录音降噪通常涉及使用音频处理技术和库来减少环境噪音。一个常见的降噪方案是使用苹果的**AVAudioEngine**结合Core Audio进行音频处理。
## 具体代码实现
以下是一个简单的示例，展示了如何在录音时进行基本的降噪处理：
```swift
import UIKit
import AVFoundation

class ViewController: UIViewController {

    var audioEngine: AVAudioEngine!
    var audioRecorder: AVAudioRecorder!

    override func viewDidLoad() {
        super.viewDidLoad()
        setupAudio()
    }

    func setupAudio() {
        audioEngine = AVAudioEngine()
        let audioSession = AVAudioSession.sharedInstance()

        do {
            try audioSession.setCategory(.playAndRecord, mode: .default)
            try audioSession.setActive(true, options: .notifyOthersOnDeactivation)

            let inputNode = audioEngine.inputNode
            let format = inputNode.inputFormat(forBus: 0)

            // 添加降噪效果
            let noiseReduction = AVAudioUnitEffect()
            // 设置降噪参数
            // noiseReduction.loadFactoryPreset(.multiChannelMixer)
            // noiseReduction.auAudioUnit = AVAudioUnitReverb()
            // ...

            audioEngine.attach(noiseReduction)
            audioEngine.connect(inputNode, to: noiseReduction, format: format)
            audioEngine.connect(noiseReduction, to: audioEngine.mainMixerNode, format: format)

            let url = getDocumentsDirectory().appendingPathComponent("recording.wav")
            let settings: [String: Any] = [
                AVFormatIDKey: kAudioFormatLinearPCM,
                AVSampleRateKey: 44100.0,
                AVNumberOfChannelsKey: 1,
                AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
            ]

            audioRecorder = try AVAudioRecorder(url: url, settings: settings)
            audioRecorder.prepareToRecord()

            try audioEngine.start()
            audioRecorder.record()

        } catch {
            print("Error setting up audio: \(error.localizedDescription)")
        }
    }

    func getDocumentsDirectory() -> URL {
        FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)[0]
    }
}

```
这段代码演示了如何使用**AVAudioEngine**在录音时添加一个音频效果（降噪效果）。你可以通过设置不同的音频效果单元和参数来实现不同的降噪处理。
需要注意的是，降噪处理通常需要更加复杂的音频处理技术和算法，并且在不同的环境和应用场景中效果可能会有所不同。在实际应用中，可能需要进一步调整参数和音频处理技术以获得更好的降噪效果。
## AVAudioUnitEffect
**AVAudioUnitEffect**是**AVFoundation**框架中的一个类，用于表示音频处理效果单元。这个类是一个抽象类，其具体子类（如**AVAudioUnitReverb**、**AVAudioUnitDelay**等）提供了不同的音频效果。
**AVAudioUnitEffect**类本身并没有公开的属性或方法来直接控制参数。具体的音频效果单元类（如**AVAudioUnitReverb**）提供了自己的属性和方法来控制特定效果的参数。以下是一些常见的音频效果单元和可能控制的参数：
### AVAudioUnitReverb

- **wetDryMix:** 控制干/湿比例，决定了混响效果与原始音频的比例。
- **gain:** 控制混响的整体音量。
### AVAudioUnitDelay

- **delayTime:** 设置延迟的时间。
- **feedback:** 控制反馈效果，影响延迟声音的衰减程度。
- **lowPassCutoff:** 设置延迟声音的低通滤波器截止频率。
### AVAudioUnitDistortion

- **preGain:** 设置失真之前的增益。
- **wetDryMix:** 控制失真效果与原始音频的比例。
### AVAudioUnitEQ

- **bands:** 控制不同频段的均衡器设置，例如增益、频率和带宽等。

以上仅是一些常见音频效果单元及其可能控制的参数，不同的效果单元具有不同的参数和功能。你可以查阅相关文档或使用Xcode的自动补全功能来查看特定音频效果单元类的属性和方法，以获取更详细的参数信息。
## 实际场景处理
在出租车行驶和语音导航等嘈杂环境下，想要获得良好的录音效果可能会更具挑战性。以下是一些建议，希望能帮助你设置AVAudioUnitEffect以获得较好的效果：
### 降噪参数设置建议

1. 降噪参数设置建议：
**频率范围调整**： 除了考虑低频（车辆引擎声）外，还需考虑导航指令和车内环境噪音等高频声音。尝试在不同频率范围内进行有效的噪音抑制。
**降噪算法优化**： 使用能够适应动态环境的降噪算法，可能需要根据不同噪音源（发动机、导航指令等）的动态变化进行实时调整。
2. **AVAudioUnitEffect**参数调整建议：
**AVAudioUnitReverb**：
湿/干比例调整： 尝试降低混响效果的湿度，以减少导航指令和车内声音的混响，使录音更加清晰。
整体音量控制： 考虑适当增加混响效果的整体音量，以补充因降噪而减少的声音。
**AVAudioUnitDelay**：
延迟时间调整： 适当调整延迟时间，使得录音声音与车辆发动机声和导航指令之间有时间间隔，减少混音效应。
3. **实时调整与测试**：
在实际录音中，通过实时调整参数和反复测试，以找到最佳的录音效果。在车辆行驶和导航指令播放的不同情况下，可能需要动态地调整参数。

**AVAudioUnitEffect** 是 iOS 和 macOS 中处理音频的一个强大工具，它是 **AVFoundation** 框架中的一部分。通过使用不同类型的 **AVAudioUnitEffect**，你可以在音频信号中添加各种效果，包括降噪效果。不过，需要注意的是，**AVAudioUnitEffect** 本身并不直接提供一个专门的降噪组件，而是需要通过配置和组合现有的音频效果来实现降噪。
要实现降噪，你可以考虑以下方法：
### 1. 使用带通滤波器
通过设置带通滤波器，你可以允许特定频率范围的信号通过，同时阻止其他频率，这有助于减少一些类型的背景噪音。
### 2. 配置动态处理器
使用 **AVAudioUnitDynamicsProcessor**，你可以配置噪声门限（noise gate）、压缩器和扩展器。噪声门限可以帮助减少低于特定阈值的噪音。
### 3. 利用第三方库
考虑集成专门用于降噪的第三方库。一些音频处理库可能提供了更高级的降噪功能。
### 示例代码
以下是一个简单的例子，展示了如何在 **AVAudioEngine** 中添加一个带通滤波器：
更适合过滤汽车发动机噪音的场景，我们需要考虑发动机噪音的特点。发动机噪音通常包含低频成分，因此可能需要一个低通滤波器来减少这些频率范围内的噪音。同时，也可以考虑使用噪声门限来进一步降低低于特定阈值的噪音。下面是一个示例代码：
```swift
import AVFoundation

let audioEngine = AVAudioEngine()

// 创建低通滤波器
let lowPassFilter = AVAudioUnitEQ(numberOfBands: 1)
if let filterParams = lowPassFilter.bands.first {
    filterParams.filterType = .lowPass
    filterParams.frequency = 300  // 调整频率以适应发动机噪音
}

// 创建动态处理器（用于噪声门限）
let dynamicsProcessor = AVAudioUnitDynamicsProcessor()
dynamicsProcessor.threshold = -20 // 调整阈值以适应环境
dynamicsProcessor.headRoom = 5
dynamicsProcessor.expansionRatio = 2
dynamicsProcessor.attackTime = 0.001
dynamicsProcessor.releaseTime = 0.05

let inputNode = audioEngine.inputNode
let format = inputNode.outputFormat(forBus: 0)

audioEngine.attach(lowPassFilter)
audioEngine.attach(dynamicsProcessor)

audioEngine.connect(inputNode, to: lowPassFilter, format: format)
audioEngine.connect(lowPassFilter, to: dynamicsProcessor, format: format)
audioEngine.connect(dynamicsProcessor, to: audioEngine.mainMixerNode, format: format)

do {
    try audioEngine.start()
} catch {
    print("Error starting audio engine: \(error)")
}
```
### 代码说明

- **低通滤波器**：设置了一个低通滤波器，其频率设置为300Hz（这个值可以根据实际情况调整），以减少发动机噪音中的低频部分。
- **动态处理器**：配置了一个动态处理器作为噪声门限，用于减少低于特定阈值的噪音。阈值、HeadRoom、扩展比率、攻击时间和释放时间都是可以调整的参数，应根据实际噪声特性进行微调。
### 注意事项

- 调整滤波器参数以适应具体的噪声环境是一个试验和错误的过程，可能需要多次调整以获得最佳效果。
- 过度滤波可能会影响到有用的音频信号，因此需要在降噪和保持音质之间找到平衡。
- 实际应用中，还需考虑用户的设备和环境差异，可能需要提供一定程度的用户自定义设置。
### 注意事项

- 实际的降噪效果取决于多种因素，包括噪音的类型和音频信号的特性。
- 降噪处理可能会对音频信号的质量产生一定影响，特别是过度处理可能导致音质降低。
- 实现高效的降噪可能需要对音频处理有深入的理解，包括对信号处理理论的了解。
- 在实际应用中，可能需要根据特定的录音条件和所需的音频质量进行细致的调整。

   要注意的是，车辆行驶和语音导航等环境噪音是比较复杂和多变的，不同噪音源之间可能会相互干扰。因此，在录音时可能需要通过不断尝试和调整来平衡降噪效果和语音清晰度，以获得最佳的录音质量
## 其他方案
### 用Apple的音频处理库Accelerate
Apple的Accelerate框架提供了许多信号处理和数字信号处理功能，可以用于音频降噪。这包括FFT、滤波器设计等功能。
```swift
import Accelerate

// 进行FFT处理、频谱分析和滤波等信号处理操作
// 可以针对特定频率或频段的噪声进行处理
```
### 使用Core Audio进行定制音频处理
Core Audio框架提供了更低层次的音频处理功能，可以对音频数据进行更精细的处理和控制。但这需要更深入的音频编程知识。
在实际开发中，需要根据具体的降噪需求和算法选择合适的技术和库，并结合实际的音频数据来进行测试和优化。以上示例仅作为指导，实际的降噪实现可能会更加复杂，并需要结合更多的信号处理技术和算法。
## WebRTC降噪方案是否有效
WebRTC（Web Real-Time Communication）中的降噪功能通常是为了改善网络通信中的音频质量而设计的。然而，对于像发动机声和语音导航等多种噪声源，WebRTC中的通用降噪算法可能并不总是有效。
WebRTC的降噪功能主要依赖于数字信号处理（DSP）算法来识别并减少常见的环境噪声，如背景噪声、风噪声等。但对于高频噪声（如语音导航）、低频噪声（如发动机声）等较为复杂或特殊的噪声源，通用的降噪算法可能效果不佳。
在高速行驶的汽车中，发动机声和风噪声通常在低频范围内，这可能会影响语音识别或通信质量。而语音导航等声音通常集中在高频范围。WebRTC的降噪算法可能不够针对性，难以有效处理不同频率和声音特征的多种噪声源。
对于这种情况，通常需要专门设计的、针对特定噪声的降噪算法或处理流程。这可能涉及到基于声学模型的算法、深度学习模型、自适应滤波器等更为高级的信号处理技术。这些技术可能需要针对特定噪声源进行训练和调整，才能更有效地降低复杂环境中的噪声干扰。
因此，WebRTC中的通用降噪功能可能对特定的发动机声和语音导航等特殊噪声源的降噪效果不佳。针对这些情况，可能需要额外的定制化处理或更专业的降噪技术。
## 推荐阅读
[https://github.com/cpuimage/WebRTC_NS](https://github.com/cpuimage/WebRTC_NS)
[https://blog.csdn.net/u011897062/article/details/111191182](https://blog.csdn.net/u011897062/article/details/111191182)
[https://zhuanlan.zhihu.com/p/619479170](https://zhuanlan.zhihu.com/p/619479170)
[https://github.com/orgs/webrtc/repositories?type=all](https://github.com/orgs/webrtc/repositories?type=all)
[https://www.cnblogs.com/mod109/p/5469799.html](https://www.cnblogs.com/mod109/p/5469799.html)
[https://audio-joiner.com/](https://audio-joiner.com/)
