## 语音活动检测能做什么
1. 检测出语音段和非语音段（静音部分）。
2. 实现语音分割。
3. 也可用于在音频会话期间去除非语音片段,在行程中的录音通过去除非静音片段，减少了服务器存储成本，降低了服务端音频处理难度，一举多得。
4. 实现收音逻辑判断。
## VAD（Voice Activity Detection）实现方式：

1.  **使用Apple的Core Audio框架**
通过使用Core Audio框架，可以访问音频输入并进行分析，以检测声音活动和静音部分。可以使用音频队列(Audio Queue)、Audio Unit或者AVAudioEngine等组件来捕获音频数据流，然后使用信号处理技术（如能量检测、过零率分析等）来判断是否存在声音活动。 
2.  **使用第三方音频处理库**
一些第三方库提供了音频处理和分析的功能，可以方便地实现VAD。例如，PortAudio、WebRTC、SpeakEasy等库提供了对音频数据流进行分析的功能，并可以用于实现VAD。 
3.  **使用深度学习模型**
借助深度学习技术（如卷积神经网络、循环神经网络等），可以训练模型来进行语音活动检测。你可以使用TensorFlow或PyTorch等深度学习框架，在iOS应用中集成训练好的模型，实现对音频数据的VAD。 
4.  **使用专门的语音处理SDK**
一些专门的语音处理SDK，如Google的Speech Recognition API、Apple的Speech Framework等，提供了语音识别和相关的功能，也包含了VAD的部分功能。你可以探索这些SDK是否提供了对VAD的支持，并集成到你的应用中。 
## SileroVAD
SileroVAD是一个基于机器学习的开源语音活动检测工具。它专门用于检测语音信号中的活动部分，即语音段和非语音段（静音部分）。SileroVAD使用神经网络模型对音频数据进行分析，并根据模型的输出来判断是否存在语音活动。
这个工具主要针对嵌入式设备和移动端应用设计，旨在提供轻量级、快速且准确的语音活动检测解决方案。它具有较高的速度和低的计算成本，适合于资源受限的环境。
SileroVAD的优势在于其高效性和准确性，能够在不消耗过多计算资源的情况下对语音信号进行较为可靠的分析。你可以在GitHub上找到相关的代码和文档，并根据需要集成到你的iOS应用中进行语音活动检测的处理。
### Silero VAD主要功能
Silero VAD在语音检测任务中具有出色的效果。

1. 快速的实时处理

 快速 单个CPU线程可以在不到1ms的时间内处理一个音频块（30+ ms）[参见](https://link.zhihu.com/?target=https%3A//github.com/snakers4/silero-vad/wiki/Performance-Metrics%23silero-vad-performance-metrics)。使用批处理或GPU也可以显著提高性能。在某些条件下，ONNX甚至可以运行得更快4-5倍。

1. 轻量的轻量级

 轻量级 JIT模型的大小约为1MB。

1. 大规模的数据训练

 Silero VAD是在包括100多种语言的庞大语料库上进行训练的，它在不同背景噪声和质量水平的不同领域的音频上表现良好。

1. 灵活的采样率

 Silero VAD支持8000 Hz和16000 Hz（PyTorch JIT）以及16000 Hz（ONNX）采样率。

1. 灵活的音频块大小

 模型在不同长度的音频块上进行训练。直接支持30ms、60ms和100ms长的块，其他块也可以工作。

1. 高度可移植

 Silero VAD受益于围绕PyTorch和ONNX构建的丰富生态系统，在这些运行时可用的地方运行。
![](https://cdn.nlark.com/yuque/0/2023/png/12719710/1700297608661-28aa6674-0b9e-440c-ba04-0780514afd78.png#averageHue=%23f8f8f8&clientId=u6c29501c-f7ea-4&from=paste&id=uea76b56c&originHeight=528&originWidth=899&originalType=url&ratio=2&rotation=0&showTitle=false&status=done&style=none&taskId=u8bc3a081-cd12-41de-bc1f-0fdda86c738&title=)
## ![image.png](https://cdn.nlark.com/yuque/0/2023/png/12719710/1700297628652-e7eec40a-14dd-4a9a-ac34-149a02460c80.png#averageHue=%23b6b7af&clientId=u6c29501c-f7ea-4&from=paste&height=156&id=ueff6cb7f&originHeight=311&originWidth=1280&originalType=binary&ratio=2&rotation=0&showTitle=false&size=341420&status=done&style=none&taskId=u3f6fe48e-0854-4586-bb5e-e7058903543&title=&width=640)
![image.png](https://cdn.nlark.com/yuque/0/2023/png/12719710/1700297651789-22eff113-98ba-459f-86e7-e454d34b4698.png#averageHue=%23f8f8f8&clientId=u6c29501c-f7ea-4&from=paste&height=657&id=uc5c3c629&originHeight=1236&originWidth=1178&originalType=binary&ratio=2&rotation=0&showTitle=false&size=135478&status=done&style=none&taskId=u02a6d1db-473a-40ec-91c2-eca70593142&title=&width=626)
## FVAD
FVAD（Free Voice Activity Detector）是一个由Google开发的开源语音活动检测器，用于检测语音信号中的活动和非活动部分。与SileroVAD类似，FVAD专门用于检测语音段和静音段，可用于语音识别、音频处理等应用中。
FVAD使用了GMM-HMM（Gaussian Mixture Model - Hidden Markov Model）的模型，通过对音频数据进行频谱分析和特征提取，然后基于声学特征进行语音活动的检测。它能够高效地处理音频数据，具有较高的准确性和低的计算成本，适合于嵌入式设备和移动端应用。
![IMG_4174.jpg](https://cdn.nlark.com/yuque/0/2023/jpeg/12719710/1700297797618-b84c1436-f58b-4500-90b6-e60ee6fe24fa.jpeg#averageHue=%23fdfdfc&clientId=u6c29501c-f7ea-4&from=paste&height=774&id=ube2ad3f8&originHeight=1547&originWidth=1170&originalType=binary&ratio=2&rotation=0&showTitle=false&size=100687&status=done&style=none&taskId=uf12b1edf-59ef-496b-8294-e75aad90dd5&title=&width=585)
## 语音裁截与合并
在iOS中，语音VAD（Voice Activity Detection）用于检测语音信号的活动或静默部分。裁截（Trimming）和合并（Merging）语音段落是对检测到的语音活动和静默部分进行处理的常见操作。下面是一个简单的示例，展示了如何使用AVAudioFile和AVMutableComposition来实现语音裁截和合并。
### 裁截（Trimming）
```swift
import AVFoundation

func trimAudio(filePath: String, startTime: TimeInterval, endTime: TimeInterval, completion: @escaping (URL?) -> Void) {
    let fileURL = URL(fileURLWithPath: filePath)
    
    do {
        let audioFile = try AVAudioFile(forReading: fileURL)
        
        let startTime = AVAudioFramePosition(startTime * audioFile.fileFormat.sampleRate)
        let endTime = AVAudioFramePosition(endTime * audioFile.fileFormat.sampleRate)
        let frameRange = AVAudioTimeRange(start: AVAudioFramePosition(startTime), duration: AVAudioFrameCount(endTime - startTime))
        
        let outputFileURL = URL(fileURLWithPath: NSTemporaryDirectory() + "trimmedAudio.m4a")
        let outputSettings: [String: Any] = [
            AVFormatIDKey: kAudioFormatMPEG4AAC,
            AVSampleRateKey: audioFile.fileFormat.sampleRate,
            AVNumberOfChannelsKey: audioFile.fileFormat.channelCount
        ]
        
        let outputFile = try AVAudioFile(forWriting: outputFileURL, settings: outputSettings)
        try outputFile.write(from: audioFile, from: frameRange)
        
        completion(outputFileURL)
    } catch {
        print("Error trimming audio: \(error.localizedDescription)")
        completion(nil)
    }
}


```
### 合并（Merging）
```swift
func mergeAudio(audioURLs: [URL], completion: @escaping (URL?) -> Void) {
    let composition = AVMutableComposition()
    
    for audioURL in audioURLs {
        let asset = AVURLAsset(url: audioURL)
        let track = composition.addMutableTrack(withMediaType: .audio, preferredTrackID: kCMPersistentTrackID_Invalid)
        
        do {
            try track?.insertTimeRange(CMTimeRangeMake(start: .zero, duration: asset.duration), of: asset.tracks(withMediaType: .audio)[0], at: composition.duration)
        } catch {
            print("Error adding audio track: \(error.localizedDescription)")
            completion(nil)
        }
    }
    
    let outputFileURL = URL(fileURLWithPath: NSTemporaryDirectory() + "mergedAudio.m4a")
    guard let exporter = AVAssetExportSession(asset: composition, presetName: AVAssetExportPresetAppleM4A) else {
        completion(nil)
        return
    }
    
    exporter.outputURL = outputFileURL
    exporter.outputFileType = .m4a
    
    exporter.exportAsynchronously {
        switch exporter.status {
        case .completed:
            completion(outputFileURL)
        default:
            completion(nil)
        }
    }
}

```
## 推荐阅读
[语音活动检测](https://mp.weixin.qq.com/s/omIvmO1ESlKeC_rSN5_FPQ)
[libfvad](https://github.com/dpirch/libfvad)
[https://github.com/msching/MCAudioInputQueue](https://github.com/msching/MCAudioInputQueue)
[使用libfvad进行实时录音人声检测(安卓和iOS) - rome753 - 博客园](https://www.cnblogs.com/rome753/p/17427445.html)
[http://www.ddrj.com/smartivr/vad.html](http://www.ddrj.com/smartivr/vad.html)
[silero-vad](https://github.com/snakers4/silero-vad)
[Voice_activity_detection](https://en.wikipedia.org/wiki/Voice_activity_detection)
[webrtc](https://gitee.com/bluefoxah/webrtc/tree/master)
